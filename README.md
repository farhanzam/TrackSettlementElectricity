## Let there be Light – Using DeepLabV3 to Track Electricity in Settlements
### Spring 2024 CS 175: Project in AI
#### Cloud 9: Azra Zahin, Farhan Zaman, Robert Alejandre, Sartaj Dua

![PyTorch](https://img.shields.io/badge/PyTorch-%23EE4C2C.svg?style=for-the-badge&logo=PyTorch&logoColor=white)
![PyTorch Lightning](https://img.shields.io/badge/PyTorch%20Lightning-%233F4F75.svg?style=for-the-badge&logo=PyTorchLightning&logoColor=white)
![NumPy](https://img.shields.io/badge/numpy-%23013243.svg?style=for-the-badge&logo=numpy&logoColor=white)
![Weights and Biases](https://img.shields.io/badge/Weights%20and%20Biases-%23d9ead3.svg?style=for-the-badge&logo=xarray&logoColor=white)
![scikit-learn](https://img.shields.io/badge/scikit--learn-%23F7931E.svg?style=for-the-badge&logo=scikit-learn&logoColor=white)

[[Tech Memo](https://docs.google.com/document/d/1UPTo1AiPCghccyAzzVWjX47emsMqU3kNXe3JUH6iP6s/edit)] [[Presentation](https://docs.google.com/presentation/d/11-HFdL29Qqu6io20S3cFUfD73-_cIiIXGMsBia5dZpc/edit#slide=id.g225d57f3b19_0_80)] [[Poster](https://docs.google.com/presentation/d/1NjSooWRQ-vqdeMPHSAke-xMA4gS2srp8MuMlfL6Ql9U/edit#slide=id.p1)] [[Video](https://youtu.be/vk8LQVT42yU)]

## Table of Contents
* [Overview of Project Artchitecture](#overview-of-project-architecture)
* [Installation](#installation)
* [Getting Started](#getting-started)
* [License](#license)
* [Citing our Work](#citing-our-work)


<a name="overview-of-project-artchitecture"></a>
## Overview of Project Architecture
Our goal was to perform semantic segmentation on various satellite images from sub-Saharan Africa to classify regions in 1 of the 4 categories:
1. Human settlements without electricity (region of interest!)
2. No human settlements without electricity
3. Human settlements with electricity
4. No human settlements with electricity

<img width="479" alt="Screenshot 2024-06-12 131535" src="https://github.com/cs175cv-s2024/final-project-cloud-9/assets/108291232/4aa37dce-a3af-4e91-a2bd-8ba249f1f990">

To do so, we implemented the DeepLabV3 ResNet-101 model from PyTorch with transfer learning. It has been trained on the IEEE GRSS 2021 Challenge [ESD dataset](https://drive.google.com/file/d/1mVDV9NkmyfZbkSiD5lkskv_MwOuYxiog/view?usp=drive_link), which is composed of 60 training tiles of 800x800 pixels, each containing 100 files from satellite images captured by Sentinel-1, Sentinel-2, Landsat 8, and VIIRS. Our model yielded ~0.78 train accuracy, ~0.62 validation accuracy, and ~0.58 F1 score on the CS175: HW3 SemSeg DSE [test data](https://www.kaggle.com/competitions/cs-175-hw-3-sem-seg-esd/data).

### Segmentation Sample/Result
![Tile40copy](https://github.com/cs175cv-s2024/final-project-cloud-9/assets/108291232/6ae59c49-9c7e-4bc2-ace8-b3187ce58bde)
![Tile44copy](https://github.com/cs175cv-s2024/final-project-cloud-9/assets/108291232/c4095b50-8281-4ef0-aaf0-40d864a0fc44)

### Pipeline
<img width="900" alt="Screenshot 2024-06-12 215624" src="https://github.com/cs175cv-s2024/final-project-cloud-9/assets/108291232/26939ef3-fde3-4170-bc70-595db53e1a0b">

<a name="installation"></a>
## Installation
This program requires `python>=3.10` and a virtual environment in your project directory.

Create a virtual environment:
- `python3 -m venv esdenv`

To activate:
- On macOS and Linux
  `source esdenv/bin/activate`
- On Windows
  `.\esdenv\Scripts\activate`
  
To install all dependencies run
`pip install -r requirements.txt`

To deactivate the virtual environment, type `deactivate`

<a name="getting-started"></a>
## Getting Started
First, make sure your data directory is set up correctly for our program expects certain paths to exist. Any additional subfolders will be auto-generated by the program.

```
ROOT
├── data
│   ├── raw
│       ├── Test
│       └── Train
```

Next, navigate to `src/utilities.py` and on lines 19-21, set the global variables to the following

```
ROOT = Path.cwd()
PROJ_NAME = "CS175-spring-2024"
MODEL = "DeepLabV3Transfer"
```

To train the model from scratch, navigate to `scripts/train.py` and run with the default arguments or optionally add your own.

`python -m <REPLACE_ME> <LIST OF PARSER ARGS (E.G. --model_type=SegmentationCNN --max_epochs=1 ...)>`

To load the model from a checkpoint, nagvigate to `models/DeepLabV3Transfer` where you will the various versions. Copy the path of the specific one you'd like to load, or stick with the default which is `last.ckpt`. 

Navigate to `scripts/evaluate.py` and run to see the plots comparing ground truth and predictions under `data/predictions/DeepLabV3Transfer`. Navigate to `scripts/evaluate_kaggle.py` and run to get the predictions on the test dataset in a .csv file under `data/predictions/DeepLabV3Transfer/results.csv`

<a name="license"></a>
## License
The model is licensed under the [MIT license](https://opensource.org/license/mit)

<a name="citing-our-work"></a>
## Citing Our Work
If you do use our implementation of DeepLabV3 with this data, please use the following BibTeX entry.
```
@article{cloud9,
  title={CS175 DeepLabV3},
  author={Azra Zahin, Farhan Zaman, Robert Alejandre, Sartaj Dua},
  year={2024}
}
```
